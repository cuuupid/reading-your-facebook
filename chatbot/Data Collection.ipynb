{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to make a Facebook Chatbot that talks like you\n",
    "\n",
    "We're going to first need to mess with the data that we have, for that we'll need Pandas and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('threads.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:,} messages'.format(df.index.shape[0]))\n",
    "print('{:,} threads (not counting unknown)'.format(np.unique(df['thread'].values).shape[0]))\n",
    "print('{:,} unique users (not counting unknown)'.format(np.unique(df['sender'].values).shape[0]))\n",
    "print('{:,} threads with people you have blocked'.format(np.where(df['thread'].values == 'Facebook User')[0].shape[0]))\n",
    "print('{:,} messages that lack senders'.format(np.where(df['sender'].values == 'Unknown')[0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good looks!** Next let's spy on the senders and make sure everything looks good. You'll notice that I look at the top 11 instead of the top 10--this is because the **top** sender will be me since I participate in _all_ my convos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 people I talk to\n",
    "z = df.groupby('sender').size().sort_values(ascending=False).head(11)\n",
    "list(z.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 threads\n",
    "tt10 = df.groupby('thread').size().sort_values(ascending=False).head(23).index\n",
    "top10threads = list(np.concatenate((tt10[:6], tt10[7:15], tt10[16:17], tt10[18:])))\n",
    "print(top10threads)\n",
    "len(top10threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that above I messed with the array a little to skip some threads. This is because some of the threads that showed up were group chats with tons of spam and very low signal--plus, most of the replies aren't me, and there isn't consistency in speakers. As a result, I clean those out.\n",
    "\n",
    "**Next, we'll aggregate the messages so it alternates senders. This simply requires us to combine consecutive messages from one sender.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = None\n",
    "dots = dict()\n",
    "photos = dict()\n",
    "for thread in top10threads:\n",
    "    thread_df = df.groupby('thread').get_group(thread)\n",
    "    thread_df['message'].fillna('', inplace=True)\n",
    "    thread_df['sender'].fillna('', inplace=True)\n",
    "    thread_df['use'] = 0\n",
    "    SENDER = 1\n",
    "    MESSAGE = 3\n",
    "    USE = -1\n",
    "    convo = thread_df.values\n",
    "    for i, msg in enumerate(convo):\n",
    "        if i == 0: continue\n",
    "        if len(msg[MESSAGE].replace('.','').replace(' ','')) < 6 and 'yes' not in msg[MESSAGE] and 'no' not in msg[MESSAGE]:\n",
    "            if msg[SENDER] not in dots: dots[msg[SENDER]] = 0\n",
    "            dots[msg[SENDER]] += 1\n",
    "            convo[i][MESSAGE] = ''\n",
    "            continue\n",
    "        elif 'image reference' in msg[MESSAGE]:\n",
    "            if msg[SENDER] not in photos: photos[msg[SENDER]] = 0\n",
    "            photos[msg[SENDER]] += 1\n",
    "            convo[i][MESSAGE] = ''\n",
    "            continue\n",
    "        elif msg[SENDER] == convo[i-1][SENDER]:\n",
    "            if convo[i-1][MESSAGE]: convo[i][MESSAGE] = (convo[i-1][MESSAGE] + '. ' + convo[i][MESSAGE]).replace('\\n', '. ')\n",
    "        else:\n",
    "            if convo[i-1][MESSAGE]: convo[i-1][USE] = 1\n",
    "    data = convo[convo[:, USE] == 1]\n",
    "    print(\"Retrieved message history, shape %s\" % str(data.shape))\n",
    "    if msgs is not None: msgs = np.concatenate((msgs, data), axis=0)\n",
    "    else: msgs = data\n",
    "\n",
    "print('Dot distribution: \\n' + '\\n'.join(['%s: %d' % (x, y) for x, y in sorted(list(dots.items()), key=lambda x: x[1])[::-1]]))\n",
    "print('Photos distribution: \\n' + '\\n'.join(['%s: %d' % (x, y) for x, y in sorted(list(photos.items()), key=lambda x: x[1])[::-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, let's write it out to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Built dataset of {:,} messages\".format(msgs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = msgs[:, 3]\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conversationData.txt', 'w') as f:\n",
    "    for _t in tqdm(text):\n",
    "        f.write(_t+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('conversationData.txt', 'r') as f:\n",
    "    a, b = len(f.readlines()), len(text)\n",
    "    assert a >= b, \"`data.txt` contains %d messages but there are at least %d messages in dataset!\" % (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnk(l, n):\n",
    "    for i in range(0, len(l) - (len(l) % n), n):\n",
    "        yield l[i:i + n]\n",
    "pairs = np.array([(m, r) for m,r in cnk(text[:200000], 2)])\n",
    "np.save('conversationDictionary.npy', pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.load('conversationDictionary.npy').shape == pairs.shape, \"didnt save correctly\"\n",
    "print(pairs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're done! Head over to the training notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
